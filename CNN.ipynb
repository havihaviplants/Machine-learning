{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "15ZR7yD0LGNt-bcmimd56FGyS-BX8Zgal",
      "authorship_tag": "ABX9TyN1pXJv7F2OfvPsy3Vqq+QU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/havihaviplants/Machine-learning/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVSME_0W7a5l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 자신의 Google Drive 마운트하는 코드를 추가하자!\n",
        "mnist = np.load('/content/drive/MyDrive/MY Drive/mnist.npz')\n",
        "x_train = (mnist['x_train'] - np.mean(mnist['x_train'])) / np.std(mnist['x_train'])\n",
        "y_train = mnist['y_train']\n",
        "x_test = (mnist['x_test'] - np.mean(mnist['x_train'])) / np.std(mnist['x_train'])\n",
        "y_test = mnist['y_test']\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "n4acvBpW75VZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4281cc48-2091-491f-b98f-afd16319200f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "# Train Data Set\n",
        "train_dataset = TensorDataset(torch.FloatTensor(x_train), torch.LongTensor(y_train))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
        "# Test Data Set\n",
        "test_dataset = TensorDataset(torch.FloatTensor(x_test), torch.LongTensor(y_test))\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "XKO6K7s48WL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 사용 여부 확인\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-x_FADa8oq9",
        "outputId": "07d2fc74-4e44-443e-a46e-35a59f5e2762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        " def __init__(self):\n",
        "  super().__init__()\n",
        "  self.cnn = nn.Sequential(\n",
        " nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1), # [b, 1, 28, 28] -> [b, 16, 28, 28]\n",
        " nn.ReLU(True),\n",
        " nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1), # [b, 16, 28, 28] -> [b, 16, 28, 28]\n",
        " nn.ReLU(True),\n",
        " nn.MaxPool2d(2, stride=2), # [b, 16, 28, 28] -> [b, 16, 14, 14]\n",
        " nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1), # [b, 16, 14, 14] -> [b, 32, 14, 14]\n",
        " nn.ReLU(True),\n",
        " nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1), # [b, 32, 14, 14] -> [b, 32, 14, 14]\n",
        " nn.ReLU(True),\n",
        " nn.MaxPool2d(2, stride=2), # [b, 32, 14, 14] -> [b, 32, 7, 7]\n",
        " )\n",
        "  self.fc1 = nn.Linear(32 * 7 * 7, 256)\n",
        "  self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        " def forward(self, x):\n",
        "  x = self.cnn(x)\n",
        "  x = torch.flatten(x, start_dim=1)\n",
        "  x = F.relu(self.fc1(x))\n",
        "  x = self.fc2(x)\n",
        "\n",
        "  return x\n"
      ],
      "metadata": {
        "id": "F4k_nZ5l85Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "opti = Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "kD0c5dEr9J9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, criterion, data_len, opti):\n",
        " correct = 0\n",
        "\n",
        " model.train()\n",
        " for data, target in dataloader:\n",
        "  data = data.view(-1, 1, 28, 28).to(device)\n",
        "  target = target.to(device)\n",
        "\n",
        "  output = model(data)\n",
        "  loss = criterion(output, target)\n",
        "\n",
        "  opti.zero_grad()\n",
        "  loss.backward()\n",
        "  opti.step()\n",
        "\n",
        "  pred = output.max(1, keepdim=True)[1]\n",
        "  correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        " acc = 100. * correct / data_len\n",
        " return acc\n"
      ],
      "metadata": {
        "id": "rbzYgFTN9SoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, criterion, data_len):\n",
        " correct = 0\n",
        "\n",
        " model.eval()\n",
        " for data, target in dataloader:\n",
        "  data = data.view(-1, 1, 28, 28).to(device)\n",
        "  target = target.to(device)\n",
        "\n",
        "  output = model(data)\n",
        "  loss = criterion(output, target)\n",
        "\n",
        "  pred = output.max(1, keepdim=True)[1]\n",
        "  correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        " acc = 100. * correct / data_len\n",
        " return acc\n"
      ],
      "metadata": {
        "id": "Q1JqOWyD9Z5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 20\n",
        "\n",
        "for i in range(epoch):\n",
        " train_acc = train(model, train_dataloader, criterion, len(train_dataloader.dataset), opti)\n",
        " val_acc = evaluate(model, test_dataloader, criterion, len(test_dataloader.dataset))\n",
        " print(f\"[Epoch: {i:2d}], [Train Acc: {train_acc:3.4f}], [Val Acc: {val_acc:3.4f}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOPtn2t39enk",
        "outputId": "db58762f-a549-4aae-d55e-7f9976cad91f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch:  0], [Train Acc: 0.0050], [Val Acc: 0.0100]\n",
            "[Epoch:  1], [Train Acc: 0.0117], [Val Acc: 0.0100]\n",
            "[Epoch:  2], [Train Acc: 0.0100], [Val Acc: 0.0100]\n",
            "[Epoch:  3], [Train Acc: 0.0050], [Val Acc: 0.0100]\n",
            "[Epoch:  4], [Train Acc: 0.0100], [Val Acc: 0.0100]\n",
            "[Epoch:  5], [Train Acc: 0.0033], [Val Acc: 0.0100]\n",
            "[Epoch:  6], [Train Acc: 0.0050], [Val Acc: 0.0200]\n",
            "[Epoch:  7], [Train Acc: 0.0133], [Val Acc: 0.0400]\n",
            "[Epoch:  8], [Train Acc: 0.0217], [Val Acc: 0.0400]\n",
            "[Epoch:  9], [Train Acc: 0.0083], [Val Acc: 0.0400]\n",
            "[Epoch: 10], [Train Acc: 0.0133], [Val Acc: 0.0500]\n",
            "[Epoch: 11], [Train Acc: 0.0200], [Val Acc: 0.0500]\n",
            "[Epoch: 12], [Train Acc: 0.0333], [Val Acc: 0.0600]\n",
            "[Epoch: 13], [Train Acc: 0.0367], [Val Acc: 0.0700]\n",
            "[Epoch: 14], [Train Acc: 0.0250], [Val Acc: 0.0800]\n",
            "[Epoch: 15], [Train Acc: 0.0267], [Val Acc: 0.0800]\n",
            "[Epoch: 16], [Train Acc: 0.0333], [Val Acc: 0.1000]\n",
            "[Epoch: 17], [Train Acc: 0.0317], [Val Acc: 0.1300]\n",
            "[Epoch: 18], [Train Acc: 0.0433], [Val Acc: 0.1300]\n",
            "[Epoch: 19], [Train Acc: 0.0350], [Val Acc: 0.1100]\n"
          ]
        }
      ]
    }
  ]
}